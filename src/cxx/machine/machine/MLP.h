/**
 * @author Andre Anjos <andre.anjos@idiap.ch>
 * @date Wed 06 Jul 2011 16:49:13 CEST
 *
 * @brief The representation of a Multi-Layer Perceptron (MLP).
 */

#ifndef TORCH_MACHINE_MLP_H 
#define TORCH_MACHINE_MLP_H

#include <blitz/array.h>

#include "io/HDF5File.h"
#include "machine/MLP.h"

namespace Torch { namespace machine {

  /**
   * An MLP object is a representation of a Multi-Layer Perceptron. This
   * implementation is feed-forward and fully-connected. The implementation
   * allows setting of input normalization values and a global activation
   * function. References to fully-connected feed-forward networks: Bishop's
   * Pattern Recognition and Machine Learning, Chapter 5. Figure 5.1 shows what
   * we mean.
   */
  class MLP {
    
    public: //api

      /**
       * Constructor, builds a new MLP. Internal values are uninitialized. In
       * this case, the number of hidden layers equals 1 and its size can be
       * defined by the middle parameter.
       *
       * @param input Size of input vector
       * @param hidden Size of the hidden layer
       * @param output Size of output vector
       * @param bias If we should bias hidden and output nodes
       */
      MLP (size_t input, size_t hidden, size_t output, bool bias=true);

      /**
       * Constructor, builds a new MLP. Internal values are uninitialized. With
       * this constructor you can control the number of hidden layers your MLP
       * will have.
       *
       * @param input Size of input vector 
       * @param hidden The number and size of each hidden layer 
       * @param output Size of output vector
       * @param bias If we should bias hidden and output nodes
       */
      MLP (size_t input, std::vector<size_t> hidden, size_t output, 
          bool bias=true);

      /**
       * Copies another machine
       */
      MLP (const MLP& other);

      /**
       * Starts a new MLP from an existing Configuration object.
       */
      MLP (Torch::io::HDF5File& config);

      /**
       * Just to virtualise the destructor
       */
      virtual ~MLP();

      /**
       * Assigns from a different machine
       */
      MLP& operator= (const MLP& other);

      /**
       * Loads data from an existing configuration object. Resets the current
       * state.
       */
      void load (Torch::io::HDF5File& config);

      /**
       * Saves an existing machine to a Configuration object.
       */
      void save (Torch::io::HDF5File& config) const;

      /**
       * Forwards data through the network, outputs the values of each output.
       *
       * The input and output are NOT checked for compatibility each time. It
       * is your responsibility to do it.
       */
      void forward_ (const blitz::Array<double,1>& input,
          blitz::Array<double,1>& output) const;

      /**
       * Forwards data through the network, outputs the values of each linear
       * component the input signal is decomposed at.
       *
       * The input and output are checked for compatibility each time the
       * forward method is applied.
       */
      void forward (const blitz::Array<double,1>& input,
          blitz::Array<double,1>& output) const;

      /**
       * Resizes the machine. If either the input or output increases in size,
       * the weights and other factors should be considered uninitialized. If
       * the size is preserved or reduced, already initialized values will not
       * be changed. 
       */
      void resize (size_t input, size_t hidden, size_t output, bool bias=true);

      /**
       * Resizes the machine. If either the input or output increases in size,
       * the weights and other factors should be considered uninitialized. If
       * the size is preserved or reduced, already initialized values will not
       * be changed. 
       */
      void resize (size_t input, std::vector<size_t> hidden, size_t output, 
          bool bias=true);

      /**
       * Returns the number of inputs expected by this machine
       */
      inline size_t inputSize () const { return m_weight.extent(0); }

      /**
       * Returns the number of outputs generated by this machine
       */
      inline size_t outputSize () const { return m_weight.extent(1); }

      /**
       * Returns the input subtraction factor
       */
      inline const blitz::Array<double, 1>& getInputSubraction() const
      { return m_input_sub; }

      /**
       * Sets the current input subtraction factor. We will check that the
       * number of inputs (first dimension of weights) matches the number of
       * values currently set and will raise an exception if that is not the
       * case.
       */
      void setInputSubtraction(const blitz::Array<double,1>& v);

      /**
       * Sets all input subtraction values to a specific value.
       */
      inline void setInputSubtraction(double v) { m_input_sub = v; }

      /**
       * Returns the input division factor
       */
      inline const blitz::Array<double, 1>& getInputDivision() const
      { return m_input_div; }

      /**
       * Sets the current input division factor. We will check that the number
       * of inputs (first dimension of weights) matches the number of values
       * currently set and will raise an exception if that is not the case.
       */
      void setInputDivision(const blitz::Array<double,1>& v);

      /**
       * Sets all input division values to a specific value.
       */
      inline void setInputDivision(double v) { m_input_div = v; }

      /**
       * Returns the weights of all layers.
       */
      inline const std::vector<blitz::Array<double, 2> >& getWeights() const 
      { return m_weight; }

      /**
       * Sets weights for all layers. The number of inputs and total number of
       * weights should be the same as set before, or this method will raise.
       * If you would like to set this MLP to a different weight configuration,
       * consider first using resize().
       */
      void setWeights(std::vector<const blitz::Array<double,2> >& weight);

      /**
       * Sets all weights to a single specific value.
       */
      inline void setWeights(double v) { m_weight = v; }

      /**
       * Returns the biases of this classifier, for every hidden layer and
       * output layer we have.
       */
      inline const std::vector<blitz::Array<double, 1> >& getBiases() const 
      { return m_bias; }

      /**
       * Sets the current biases. We will check that the number of biases
       * matches the number of weights (first dimension) currently set and
       * will raise an exception if that is not the case.
       */
      void setBiases(const std::vector<blitz::Array<double,1> >& bias);

      /**
       * Sets all output bias values to a specific value.
       */
      inline void setBiases(double v) { m_bias = v; }

      /**
       * Returns the currently set activation function
       */
      inline Activation getActivation() const { return m_activation; }

      /**
       * Sets the activation function for each of the outputs.
       */
      void setActivation(Activation a);

    private: //representation

      typedef double (*actfun_t)(double); ///< activation function type

      blitz::Array<double, 1> m_input_sub; ///< input subtraction
      blitz::Array<double, 1> m_input_div; ///< input division
      blitz::Array<double, 2> m_weight; ///< weights
      blitz::Array<double, 1> m_bias; ///< biases for the output
      Activation m_activation; ///< currently set activation type
      actfun_t m_actfun; ///< currently set activation function

      mutable blitz::Array<double, 1> m_buffer; ///< a buffer for speed
  
  };

}}

  };

}}

#endif /* TORCH_MACHINE_MLP_H */
